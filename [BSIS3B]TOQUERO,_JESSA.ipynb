{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLzpcsXxpFAw",
        "outputId": "ccad5a09-27f3-4f01-a901-3c12329b2a8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.35.0-py2.py3-none-any.whl (8.6 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.1-py3-none-manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.6.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Installing collected packages: watchdog, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.35.0 watchdog-4.0.1\n",
            "Collecting img2vec_pytorch\n",
            "  Downloading img2vec_pytorch-1.0.1-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from img2vec_pytorch) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from img2vec_pytorch) (0.18.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from img2vec_pytorch) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->img2vec_pytorch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->img2vec_pytorch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->img2vec_pytorch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->img2vec_pytorch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->img2vec_pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->img2vec_pytorch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->img2vec_pytorch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->img2vec_pytorch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->img2vec_pytorch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->img2vec_pytorch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->img2vec_pytorch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->img2vec_pytorch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->img2vec_pytorch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->img2vec_pytorch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->img2vec_pytorch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->img2vec_pytorch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->img2vec_pytorch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->img2vec_pytorch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->img2vec_pytorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->img2vec_pytorch) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->img2vec_pytorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->img2vec_pytorch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, img2vec_pytorch\n",
            "Successfully installed img2vec_pytorch-1.0.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting scikit-learn==1.4.2\n",
            "  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2) (3.5.0)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "Successfully installed scikit-learn-1.4.2\n",
            "Collecting st_pages\n",
            "  Downloading st_pages-0.4.5-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: streamlit>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from st_pages) (1.35.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.10.0->st_pages) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit>=1.10.0->st_pages) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.10.0->st_pages) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.10.0->st_pages) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.10.0->st_pages) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.10.0->st_pages) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.10.0->st_pages) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.10.0->st_pages) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.10.0->st_pages) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.10.0->st_pages) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.10.0->st_pages) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.10.0->st_pages) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.10.0->st_pages) (8.3.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.10.0->st_pages) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.10.0->st_pages) (4.12.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.10.0->st_pages) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.10.0->st_pages) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.10.0->st_pages) (6.3.3)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.10.0->st_pages) (4.0.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=1.10.0->st_pages) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=1.10.0->st_pages) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=1.10.0->st_pages) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=1.10.0->st_pages) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.10.0->st_pages) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit>=1.10.0->st_pages) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit>=1.10.0->st_pages) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit>=1.10.0->st_pages) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=1.10.0->st_pages) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=1.10.0->st_pages) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=1.10.0->st_pages) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=1.10.0->st_pages) (2024.6.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=1.10.0->st_pages) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=1.10.0->st_pages) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.10.0->st_pages) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit>=1.10.0->st_pages) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.10.0->st_pages) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.10.0->st_pages) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.10.0->st_pages) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.10.0->st_pages) (0.18.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=1.10.0->st_pages) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit>=1.10.0->st_pages) (1.16.0)\n",
            "Installing collected packages: st_pages\n",
            "Successfully installed st_pages-0.4.5\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit\n",
        "!pip install img2vec_pytorch\n",
        "!pip install scikit-learn==1.4.2\n",
        "!pip install st_pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P58XLegoRqgD",
        "outputId": "6f12ef18-f89f-489d-a974-6a76a726323a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting croprecom.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile croprecom.py\n",
        "import numpy as np\n",
        "import pickle\n",
        "import streamlit as st\n",
        "import sklearn\n",
        "model=pickle.load(open(\"trained_model.sav\",'rb'))\n",
        "#model=pickle.load(open(\"..train_model.sav\",'rb'))\n",
        "\n",
        "crops=['rice', 'maize', 'chickpea', 'kidneybeans', 'pigeonpeas',\n",
        "       'mothbeans', 'mungbean', 'blackgram', 'lentil', 'pomegranate',\n",
        "       'banana', 'mango', 'grapes', 'watermelon', 'muskmelon', 'apple',\n",
        "       'orange', 'papaya', 'coconut', 'cotton', 'jute', 'coffee']\n",
        "crops.sort()\n",
        "labels=[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
        "       17, 18, 19, 20, 21]\n",
        "label_crops=dict(zip(labels,crops))\n",
        "html_code = '''\n",
        "<h1 style=\"color:blue; text-align:center\">Crop Recommendation System</h1>\n",
        "'''\n",
        "## Function to predict which crop is best suited for particular region\n",
        "def CropRecommendation(input_data):\n",
        "\n",
        "    input_data=np.array(input_data).reshape(1,-1)\n",
        "    recommend=model.predict(input_data)\n",
        "    print(recommend)\n",
        "    print(label_crops[recommend[0]])\n",
        "    return label_crops[recommend[0]]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    st.markdown(html_code,unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "\n",
        "    #Required Data\n",
        "# Nitrogen, Phosphorous,Potassium,Temperature,Rainfall,Ph\n",
        "    nitrogen=st.text_input(\"Enter Nitrogen content in soil \")\n",
        "    phosphorous=st.text_input(\"Enter Phosphorous content in soil \")\n",
        "    potassium=st.text_input(\"Enter Potassium content in soil \")\n",
        "    temperature=st.text_input(\"Enter Temperature in Celsius\")\n",
        "    humidity=st.text_input(\"Enter relative humidity in %\")\n",
        "    ph=st.text_input(\"Enter ph value of the soil\")\n",
        "    rainfall=st.text_input(\"Enter rainfall in mm\")\n",
        "\n",
        "    BestCrop=\"\"\n",
        "    if st.button(\"Recommend Crop\"):\n",
        "\n",
        "        print(nitrogen)\n",
        "        if( nitrogen and  phosphorous and  potassium and  temperature and  rainfall and ph and humidity):\n",
        "            BestCrop=CropRecommendation([int(nitrogen),int(phosphorous),int(potassium),float(temperature),float(humidity),float(ph),float(rainfall)])\n",
        "            st.success(BestCrop)\n",
        "        else :\n",
        "            st.write(\"Enter Correct Values\")\n",
        "if __name__=='__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u45slab7SpY-",
        "outputId": "7a851ce5-d5ec-4a1b-bb93-45fa1ca048d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting analyzer.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile analyzer.py\n",
        "\n",
        "import streamlit as st\n",
        "import pickle\n",
        "import numpy as np\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "\n",
        "# Define features (words) and their corresponding labels (emotions)\n",
        "def word_features(words):\n",
        "    return dict([(word, True) for word in words])\n",
        "\n",
        "# Define emotions and their associated words\n",
        "emotions = {\n",
        "    'happy': ['happy', 'joyful', 'excited'],\n",
        "    'sad': ['sad', 'unhappy', 'depressed'],\n",
        "    'angry': ['angry', 'mad', 'furious'],\n",
        "    'excited': ['excited', 'thrilled', 'eager'],\n",
        "    'nervous': ['nervous', 'anxious', 'worried'],\n",
        "    'scared': ['scared', 'fearful', 'terrified']\n",
        "}\n",
        "\n",
        "# Generate training set for each emotion\n",
        "train_set = [(word_features(word.split()), emotion)\n",
        "             for emotion, words in emotions.items()\n",
        "             for word in words]\n",
        "\n",
        "# Train the Naive Bayes classifier\n",
        "classifier = NaiveBayesClassifier.train(train_set)\n",
        "\n",
        "# Function to predict emotions\n",
        "def predict_emotions(docx):\n",
        "    results = classifier.classify(word_features(docx.split()))\n",
        "    return results\n",
        "\n",
        "# Function to get prediction probabilities\n",
        "def get_prediction_proba(docx):\n",
        "    results = classifier.prob_classify(word_features(docx.split()))\n",
        "    probabilities = {label: results.prob(label) for label in results.samples()}\n",
        "    return probabilities\n",
        "\n",
        "# Function to save the trained classifier to a pickle file\n",
        "def save_model_to_pickle(model, filename):\n",
        "    with open(filename, 'wb') as file:\n",
        "        pickle.dump(model, file)\n",
        "\n",
        "# Main Application\n",
        "def main():\n",
        "    st.title(\"Emotion Classifier App\")\n",
        "\n",
        "    # Text input for user to enter a sentence\n",
        "    sentence = st.text_input(\"Enter a sentence:\")\n",
        "\n",
        "    if sentence:\n",
        "        # Classify the sentence\n",
        "        sentiment = predict_emotions(sentence)\n",
        "        probabilities = get_prediction_proba(sentence)\n",
        "\n",
        "        st.write(f\"Predicted Emotion: {sentiment}\")\n",
        "\n",
        "        st.write(\"Prediction Probabilities:\")\n",
        "        for emotion, probability in probabilities.items():\n",
        "            st.write(f\"{emotion}: {probability:.4f}\")\n",
        "\n",
        "        # Button to save the trained classifier to a pickle file\n",
        "        if st.button(\"Save Model\"):\n",
        "            save_model_to_pickle(classifier, 'trained_classifier.pkl')\n",
        "            st.success(\"Model saved to 'trained_classifier.pkl'\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_ARgwpjT4tw",
        "outputId": "11d6336a-a228-4136-f907-80b12dd27a9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting classify.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile classify.py\n",
        "\n",
        "from PIL import Image\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import os\n",
        "\n",
        "st.title(\"Fruit Identification\")\n",
        "st.header(\"Supported fruits: lemon, apple, mandarin, orange\")\n",
        "st.text(\"Upload a clear image of a fruit\")\n",
        "\n",
        "# Load fruit data\n",
        "fruit_data = pd.read_csv(\"fruit.csv\", header=None, names=[\"fruit_label\", \"mass\", \"width\", \"height\", \"color_score\", \"fruit_name\"])\n",
        "\n",
        "# Load the model if it exists\n",
        "if os.path.exists('fruit_classifier.sav'):\n",
        "    model = joblib.load('fruit_classifier.sav')\n",
        "else:\n",
        "    model = None\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Enter image\", type=[\"png\", \"jpeg\", \"jpg\"])\n",
        "\n",
        "def simulate_features(image):\n",
        "    \"\"\"Simulate mass and color score features for demonstration purposes.\"\"\"\n",
        "    # Simulating feature extraction process\n",
        "    mass = np.random.randint(50, 500)  # Random mass between 50 and 500 grams\n",
        "    color_score = np.random.uniform(0, 1)  # Random color score between 0 and 1\n",
        "\n",
        "    return mass, color_score\n",
        "\n",
        "def classify_fruit(image):\n",
        "    \"\"\"Classify the fruit based on the simulated features.\"\"\"\n",
        "    if model is None:\n",
        "        return \"Model not trained yet.\"\n",
        "\n",
        "    # Simulate feature extraction from the image\n",
        "    mass, color_score = simulate_features(image)\n",
        "\n",
        "    # Prepare feature vector\n",
        "    features = np.array([[mass, color_score]])\n",
        "\n",
        "    # Predict using the trained model\n",
        "    fruit_label = model.predict(features)[0]\n",
        "    fruit_name = fruit_data[fruit_data['fruit_label'] == fruit_label]['fruit_name'].values[0]\n",
        "\n",
        "    return fruit_name\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    image = Image.open(uploaded_file)\n",
        "    st.image(image, caption='Uploaded image', use_column_width=True)\n",
        "    st.write(\"\")\n",
        "    st.write(\"Classifying...\")\n",
        "\n",
        "    predicted_fruit = classify_fruit(image)\n",
        "\n",
        "    if predicted_fruit:\n",
        "        st.write(f\"The uploaded fruit is {predicted_fruit}.\")\n",
        "    else:\n",
        "        st.write(\"Fruit classification failed.\")\n",
        "\n",
        "    # Prepare training data\n",
        "    X = fruit_data[['mass', 'color_score']]\n",
        "    y = fruit_data['fruit_label']\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train the model\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    st.write(f\"Model accuracy: {accuracy}\")\n",
        "\n",
        "    # Save the trained model as a .sav file\n",
        "    joblib.dump(model, 'fruit_classifier.sav')\n",
        "    st.write(\"Model saved as 'fruit_classifier.sav'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PehhrcezVrBu",
        "outputId": "4f166ef2-53e3-45f5-dbde-f559aa7977bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting croprecom_src.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile croprecom_src.py\n",
        "import streamlit as st\n",
        "\n",
        "st.header('Crop Recommendation App')\n",
        "st.subheader('This model was trained using a dataset')\n",
        "st.code('''\n",
        "import numpy as np\n",
        "import pickle\n",
        "import streamlit as st\n",
        "import sklearn\n",
        "model = pickle.load(open(\"trained_model.sav\", 'rb'))\n",
        "# model = pickle.load(open(\"..train_model.sav\", 'rb'))\n",
        "\n",
        "crops = ['rice', 'maize', 'chickpea', 'kidneybeans', 'pigeonpeas',\n",
        "         'mothbeans', 'mungbean', 'blackgram', 'lentil', 'pomegranate',\n",
        "         'banana', 'mango', 'grapes', 'watermelon', 'muskmelon', 'apple',\n",
        "         'orange', 'papaya', 'coconut', 'cotton', 'jute', 'coffee']\n",
        "crops.sort()\n",
        "labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,\n",
        "          17, 18, 19, 20, 21]\n",
        "label_crops = dict(zip(labels, crops))\n",
        "\n",
        "## Function to predict which crop is best suited for particular region\n",
        "def CropRecommendation(input_data):\n",
        "    input_data = np.array(input_data).reshape(1, -1)\n",
        "    recommend = model.predict(input_data)\n",
        "    print(recommend)\n",
        "    print(label_crops[recommend[0]])\n",
        "    return label_crops[recommend[0]]\n",
        "\n",
        "def main():\n",
        "    st.markdown(html_code, unsafe_allow_html=True)\n",
        "\n",
        "    # Required Data\n",
        "    # Nitrogen, Phosphorous, Potassium, Temperature, Rainfall, Ph\n",
        "    nitrogen = st.text_input(\"Enter Nitrogen content in soil \")\n",
        "    phosphorous = st.text_input(\"Enter Phosphorous content in soil \")\n",
        "    potassium = st.text_input(\"Enter Potassium content in soil \")\n",
        "    temperature = st.text_input(\"Enter Temperature in Celsius\")\n",
        "    humidity = st.text_input(\"Enter relative humidity in %\")\n",
        "    ph = st.text_input(\"Enter ph value of the soil\")\n",
        "    rainfall = st.text_input(\"Enter rainfall in mm\")\n",
        "\n",
        "    BestCrop = \"\"\n",
        "    if st.button(\"Recommend Crop\"):\n",
        "        if (nitrogen and phosphorous and potassium and temperature and rainfall and ph and humidity):\n",
        "            BestCrop = CropRecommendation([int(nitrogen), int(phosphorous), int(potassium), float(temperature), float(humidity), float(ph), float(rainfall)])\n",
        "            st.success(BestCrop)\n",
        "        else:\n",
        "            st.write(\"Enter Correct Values\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "''')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-d8MgahV_aw",
        "outputId": "54699eb6-579e-4d5c-8cd6-2ac03f5f3963"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting analyzer_src.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile analyzer_src.py\n",
        "import streamlit as st\n",
        "\n",
        "\n",
        "st.header('Sentiment Analyzer App')\n",
        "st.subheader('This model was trained using a dataset')\n",
        "st.code('''\n",
        "\n",
        "import streamlit as st\n",
        "import pickle\n",
        "import numpy as np\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "\n",
        "# Define features (words) and their corresponding labels (emotions)\n",
        "def word_features(words):\n",
        "    return dict([(word, True) for word in words])\n",
        "\n",
        "# Define emotions and their associated words\n",
        "emotions = {\n",
        "    'happy': ['happy', 'joyful', 'excited'],\n",
        "    'sad': ['sad', 'unhappy', 'depressed'],\n",
        "    'angry': ['angry', 'mad', 'furious'],\n",
        "    'excited': ['excited', 'thrilled', 'eager'],\n",
        "    'nervous': ['nervous', 'anxious', 'worried'],\n",
        "    'scared': ['scared', 'fearful', 'terrified']\n",
        "}\n",
        "\n",
        "# Generate training set for each emotion\n",
        "train_set = [(word_features(word.split()), emotion)\n",
        "             for emotion, words in emotions.items()\n",
        "             for word in words]\n",
        "\n",
        "# Train the Naive Bayes classifier\n",
        "classifier = NaiveBayesClassifier.train(train_set)\n",
        "\n",
        "# Function to predict emotions\n",
        "def predict_emotions(docx):\n",
        "    results = classifier.classify(word_features(docx.split()))\n",
        "    return results\n",
        "\n",
        "# Function to get prediction probabilities\n",
        "def get_prediction_proba(docx):\n",
        "    results = classifier.prob_classify(word_features(docx.split()))\n",
        "    probabilities = {label: results.prob(label) for label in results.samples()}\n",
        "    return probabilities\n",
        "\n",
        "# Function to save the trained classifier to a pickle file\n",
        "def save_model_to_pickle(model, filename):\n",
        "    with open(filename, 'wb') as file:\n",
        "        pickle.dump(model, file)\n",
        "\n",
        "# Main Application\n",
        "def main():\n",
        "    st.title(\"Emotion Classifier App\")\n",
        "\n",
        "    # Text input for user to enter a sentence\n",
        "    sentence = st.text_input(\"Enter a sentence:\")\n",
        "\n",
        "    if sentence:\n",
        "        # Classify the sentence\n",
        "        sentiment = predict_emotions(sentence)\n",
        "        probabilities = get_prediction_proba(sentence)\n",
        "\n",
        "        st.write(f\"Predicted Emotion: {sentiment}\")\n",
        "\n",
        "        st.write(\"Prediction Probabilities:\")\n",
        "        for emotion, probability in probabilities.items():\n",
        "            st.write(f\"{emotion}: {probability:.4f}\")\n",
        "\n",
        "        # Button to save the trained classifier to a pickle file\n",
        "        if st.button(\"Save Model\"):\n",
        "            save_model_to_pickle(classifier, 'trained_classifier.pkl')\n",
        "            st.success(\"Model saved to 'trained_classifier.pkl'\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCnm9wuQWODe",
        "outputId": "a60ca809-356b-4899-bb0b-bf916294d1fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting classify_src.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile classify_src.py\n",
        "import streamlit as st\n",
        "\n",
        "\n",
        "st.header('Image Classification App')\n",
        "st.subheader('This model was trained using a dataset')\n",
        "st.code('''\n",
        "\n",
        "# overwrite app.py\n",
        "\n",
        "from PIL import Image\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "st.title(\"Fruit Identification\")\n",
        "st.header(\"Supported fruits: lemon, apple, mandarin, orange\")\n",
        "st.text(\"Upload a clear image of a fruit\")\n",
        "\n",
        "fruit_data = pd.read_csv(\"fruit.csv\", header=None, names=[\"fruit_label\", \"mass\", \"width\", \"height\", \"color_score\", \"fruit_name\"])\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Enter image\", type=[\"png\", \"jpeg\", \"jpg\"])\n",
        "\n",
        "def classify_fruit(image):\n",
        "    # Function to classify the fruit based on the fruit data\n",
        "\n",
        "    # Assuming you have a method to extract features from the image\n",
        "    # Here we'll just use random values for demonstration\n",
        "    mass = np.random.randint(50, 500)  # Random mass between 50 and 500 grams\n",
        "    color_score = np.random.uniform(0, 1)  # Random color score between 0 and 1\n",
        "\n",
        "    # Calculate the Euclidean distance between the features of the image and each fruit in the dataset\n",
        "    fruit_data['distance'] = np.sqrt((fruit_data['mass'] - mass)**2 +\n",
        "                                     (fruit_data['color_score'] - color_score)**2)\n",
        "\n",
        "    # Find the closest fruit based on the calculated distance\n",
        "    closest_fruit_index = fruit_data['distance'].idxmin()\n",
        "    closest_fruit = fruit_data.loc[closest_fruit_index, 'fruit_name']\n",
        "\n",
        "    return closest_fruit\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    image = Image.open(uploaded_file)\n",
        "    st.image(image, caption='Uploaded image', use_column_width=True)\n",
        "    st.write(\"\")\n",
        "    st.write(\"Classifying...\")\n",
        "\n",
        "    predicted_fruit = classify_fruit(image)\n",
        "\n",
        "    if predicted_fruit:\n",
        "        st.write(f\"The uploaded fruit is {predicted_fruit}.\")\n",
        "    else:\n",
        "        st.write(\"Fruit classification failed.\")\n",
        "\n",
        "    # Create features (for demonstration purpose)\n",
        "    X = fruit_data[['mass', 'color_score']]\n",
        "    y = fruit_data['fruit_label']\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train the model\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    st.write(f\"Model accuracy: {accuracy}\")\n",
        "\n",
        "    # Save the trained model as a .sav file\n",
        "    joblib.dump(model, 'fruit_classifier.sav')\n",
        "\n",
        "    st.write(\"Model saved as 'fruit_classifier.sav'\")\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqrzqH-bWbXF",
        "outputId": "706c2c09-3b1b-43cf-acee-4de204ea5e8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting home.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile home.py\n",
        "import streamlit as st\n",
        "from st_pages import Page, Section, show_pages, add_page_title, hide_pages\n",
        "\n",
        "add_page_title()\n",
        "show_pages(\n",
        "    [\n",
        "        Page(\"home.py\", \"ITEQMT Machine Learning Application Portfolio\", \"üíª\"),\n",
        "        Section(\"Machine Learning UI App\", \"üßô‚Äç‚ôÇÔ∏è\"),\n",
        "        Page(\"croprecom.py\", \"Crop Recommendation ML Model\", \"1Ô∏è‚É£\", in_section=True),\n",
        "        Page(\"analyzer.py\", \"Basic Sentiment Analyzer\", \"2Ô∏è‚É£\", in_section=True),\n",
        "        Page(\"classify.py\", \"Image Classification\", \"3Ô∏è‚É£\", in_section=True),\n",
        "\n",
        "        Section(\"Sample Source Code\", \"üíæ\"),\n",
        "        Page(\"croprecom_src.py\", \"Crop Recommendation SRC\", \"1Ô∏è‚É£\", in_section=True),\n",
        "        Page(\"analyzer_src.py\", \"Basic Sentiment Analyzer SRC\", \"2Ô∏è‚É£\", in_section=True),\n",
        "        Page(\"classify_src.py\", \"Image Classification SRC\", \"3Ô∏è‚É£\", in_section=True),\n",
        "    ]\n",
        ")\n",
        "\n",
        "hide_pages([\"Thank you\"])\n",
        "\n",
        "st.markdown(\"### üë®‚Äçüîß ML Learning by [JESSATOQUERO](https://github.com/JESSATOQUERO)\")\n",
        "\n",
        "st.image(\"./back.jpg\")\n",
        "st.info(\"üë®‚Äçüîß Please take note when on streamlit.app the [Image Classification] pages are not working due to Memory Limitation of 'Free Tier' hosting of Streamlit\")\n",
        "st.markdown(\"---\")\n",
        "\n",
        "with st.expander(\"About\"\"Myself\"\"\"):\n",
        "    st.markdown(\"\"\"\n",
        "\n",
        "    #\n",
        "\n",
        "      ### About Myself\n",
        "        Name: Jessa O. Toquero\n",
        "        Age: 23\n",
        "        School: Carlos Hilado Memorial State University\n",
        "        Course, Year&Section: BSIS 3B\n",
        "        Skills Learned: Html&css, js, java, php, sql, c++, and python\n",
        "\n",
        "   # Contact information\n",
        "st.info(\"For more info, contact [Toquero, Jessa O.](https://www.facebook.com/jessa.toquero.942?mibextid=JRoKGi) on Facebook\", icon=\"üìß\")\n",
        "st.info(\"Contact [Toquero, Jessa O.](https://www.instagram.com/toquero.jessa?igsh=MXdnaGY0Z2hzNzJqag==) on Instagram\", icon=\"üìß\")\n",
        "st.warning(\"Please note that when on Streamlit.app, the [Image Classification] pages might not work due to the memory limitations of 'Free Tier' hosting on Streamlit.\")\n",
        "st.markdown(\"---\")\n",
        "    #\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "st.image(\"./ml.jpg\")\n",
        "st.markdown(\"\"\"\n",
        "### üë®‚Äçüéì Read More\n",
        "\n",
        "\n",
        "##### üë®‚Äçüë¶‚Äçüë¶ Description of Apps\n",
        "\n",
        "* Prediction App is about the crop recommendation machine learning based on the required input in croprecom.py file\n",
        "* Sentiment Analyzer is about the emotion identifier of information input of how you feel or what have will you do, etc. in analyzer.py file\n",
        "* Image Classification is about the determination wether the uploaded picture is an apple, orange, lemon, or mandarin.\n",
        "\n",
        "##### üë®‚Äçüîß What I have Learned\n",
        "\n",
        " Machine learning has a rich history spanning several decades. It began in the 1940s-1950s with the foundation of AI and the introduction of neural networks by Frank Rosenblatt.\n",
        "        The 1950s-1960s saw symbolic AI using explicit rules and logic, with early programs like the Logic Theorist. From the 1960s-1980s, machine learning algorithms emerged, including the nearest neighbor algorithm and the backpropagation algorithm for neural networks. Despite an \"AI Winter\" in the 1970s-1980s, foundational work continued. The 1990s brought a resurgence with statistical methods like SVMs and ensemble methods.\n",
        "        The 2000s-2010s marked the deep learning revolution with CNNs and RNNs, significantly advancing image and sequence data processing. By the 2010s, machine learning became crucial in various fields, aided by frameworks like TensorFlow and PyTorch.\n",
        "        Key figures include Geoffrey Hinton, Yann LeCun, and Yoshua Bengio, pioneers in deep learning. Today, machine learning continues to evolve rapidly, driving innovation across numerous applications.\n",
        "\n",
        "        ### Purpose of Machine Learning\n",
        "\n",
        "        The purpose of machine learning is to enable computers to learn from data and make decisions or predictions without being explicitly programmed.\n",
        "        It aims to create systems that can automatically improve their performance over time through experience. Machine learning is used to recognize patterns, classify information, and make forecasts based on data. It helps in automating tasks, enhancing efficiency, and providing insights in various fields such as healthcare, finance, marketing, and technology. By leveraging algorithms and statistical models, machine learning enables the development of intelligent applications that can adapt and respond to new data, ultimately driving innovation and solving complex problems.\n",
        "\n",
        "        ### Usage of Machine Learning\n",
        "        Machine learning is used across various industries and applications, including:\n",
        "\n",
        "        * Healthcare: Machine learning is used to analyze medical data for diagnosing diseases, predicting patient outcomes, and personalizing treatment plans.\n",
        "        * Entertainment: It powers recommendation systems for streaming services, helping to suggest movies, shows, and music tailored to individual preferences.\n",
        "        * Transportation: Machine learning enhances autonomous driving technologies, optimizing routes, and improving safety through predictive maintenance and traffic management.\n",
        "        * Retail: Machine learning helps in demand forecasting, personalized marketing, and inventory management, enhancing customer experience and sales.\n",
        "        * Manufacturing: It enables predictive maintenance, quality control, and supply chain optimization, improving efficiency and reducing downtime.\n",
        "        * Business: It is used for financial analysis, fraud detection, and customer relationship management, driving better decision-making and operational efficiency.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ")\n",
        "\n",
        "### üîé Overview\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "st.image(\"./back.jpg\")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "              My name is Jessa O. Toquero, a 23-year-old student from Carlos Hilado Memorial State University,\n",
        "              currently enrolled in BSIS 3B. I have acquired various skills in programming languages such as HTML & CSS,\n",
        "              JavaScript, Java, PHP, SQL, C++, and Python. Through the development of my applications, I have created a\n",
        "              Prediction app that uses trained models for forecasting and estimating outcomes, a Sentiment Analyzer that\n",
        "              determines the sentiment of text data, and an Image Classification app that categorizes images using machine\n",
        "              learning models. These projects have deepened my understanding of algorithmic processes, data preparation,\n",
        "              model evaluation, and the deployment of machine learning models in user-friendly interfaces. Additionally, I\n",
        "              have improved my skills in building interactive applications with Streamlit, furthering my knowledge in both\n",
        "              programming and machine learning domains.\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "hide_streamlit_style = \"\"\"\n",
        "<style>\n",
        "#MainMenu {visibility: hidden;}\n",
        "footer {visibility: hidden;}\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "# st.markdown(hide_streamlit_style, unsafe_allow_html=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeI5TNAIpsJ0",
        "outputId": "1c4ed3af-20ea-4165-84c5-1d7c5c728d92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.83.45.192\n"
          ]
        }
      ],
      "source": [
        "! wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omDL2t_SaY6p",
        "outputId": "3d8d34ef-94e4-42da-949f-5a2186aa5e6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.83.45.192:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.352s\n",
            "your url is: https://warm-schools-sing.loca.lt\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator GaussianNB from version 1.2.1 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "! streamlit run home.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n"
      ],
      "metadata": {
        "id": "6s8kg6ejaTdG",
        "outputId": "e91867e0-d313-48e3-8c19-5949a5e78423",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.35.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.0.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.6.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "\n",
        "def main():\n",
        "    st.title(\"Hello Streamlit!\")\n",
        "    st.write(\"Welcome to Streamlit.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "pyRYt7zyamm0",
        "outputId": "9e335f47-5382-4cd3-ee36-156f5f723240",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run --server.port 8502 app.py\n",
        "\n"
      ],
      "metadata": {
        "id": "NbO8LCH1arTU",
        "outputId": "30a206e6-7cb4-4be0-be39-30fdb4ecfb1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8502\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8502\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.83.45.192:8502\u001b[0m\n",
            "\u001b[0m\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}